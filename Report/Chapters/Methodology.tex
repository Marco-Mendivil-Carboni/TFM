\chapter{Metodología}
\label{cap:methodology}

\section{Dinámica Molecular}

En particular las simulaciones de dinámica molecular (MD) \cite{Rapaport2004} son aquellas en las que se resuelven numéricamente las ecuaciones del movimiento clásicas de un sistema de muchos cuerpos. Su nombre proviene de que, en virtud de la aproximación de Born-Oppenheimer, este método se puede y se suele utilizar para estudiar el movimiento de los núcleos atómicos en las moléculas, por lo que habitualmente, en las llamadas simulaciones MD \textit{all-atom}, cada una de las partículas representa uno de estos núcleos. Cuando se quieren simular macromoléculas (como en este trabajo), en cambio, es habitual usar modelos \textit{coarse-grained} en los que cada partícula representa un grupo de átomos. Al reducir los grados de libertad son posibles tiempos de simulación mucho mayores, a costa de perder algo de detalle.

Además, generalmente las moléculas que se quieren estudiar están inmersas en un solvente (casi siempre agua en contextos biológicos), que tiene efectos importantes sobre el comportamiento del soluto. Ahora bien, introducir explícitamente en las simulaciones las moléculas del solvente, que es de escaso interés en sí mismo, requiere de una gran cantidad de recursos y no suele ser necesario. En su lugar este se suele tener en cuenta de forma implícita \cite{Leach2001}, incorporando solo sus efectos sobre las partículas de la molécula: la modulación de los potenciales efectivos que actúan sobre ellas, la resistencia viscosa a su movimiento y las colisiones aleatorias de estas con las partículas del medio. El método más empleado para lograrlo es la dinámica de Langevin, que consiste simplemente en añadir a las ecuaciones del movimiento de la dinámica molecular una fuerza de fricción proporcional a la velocidad y una fuerza aleatoria que representa el efecto de estas colisiones. Es decir, que cada una de las partículas del sistema obedece la que se conoce como una ecuación de Langevin,
\begin{equation}
    \label{eq:Langevin}
    m_i\frac{d^2\bar{r}_i}{dt^2}=-\xi_i\frac{d\bar{r}_i}{dt}-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t)
\end{equation}
donde $m_i$ es la masa de la partícula $i$, $\xi_i$ es su coeficiente cinético y $\bar{\zeta}_i(t)$ es la fuerza aleatoria sobre ella. Los coeficientes cinéticos dependen del medio y la geometría de las partículas y los estimaremos más adelante. El potencial $V$ por supuesto depende, además del medio, de la molécula que se quiera simular, o mejor dicho, del modelo que se quiera utilizar para ello y será el tema central del capítulo \dots. Por último las fuerzas aleatorias dependen del medio y de los coeficientes cinéticos tal y como vamos a ver a continuación.

En realidad $\bar{\zeta}_i(t)$ no son funciones del tiempo en el sentido matemático habitual sino procesos estocásticos gaussianos con dos propiedades fundamentales:
\begin{equation}
    \label{eq:random_forces_properties}
    \langle \zeta_i^\alpha(t) \rangle=0 \quad \text{y} \quad \langle \zeta_i^\alpha(t)\zeta_j^\beta(t') \rangle=2\xi_ik_BT\delta_{ij}\delta_{\alpha\beta}\delta(t-t') \quad \forall \ i,j=1,\dots,N \land \alpha,\beta=x,y,z
\end{equation}
donde $k_B$ es la constante de Boltzmann y $T$ es la temperatura del medio. De esta forma, la dinámica de Langevin al introducir los efectos del solvente actúa simultáneamente como un termostato, permitiendo controlar la temperatura del sistema. Se puede demostrar \cite{Coffey2012} que esta ecuación efectivamente genera trayectorias que reproducen la distribución de probabilidad canónica. De hecho la varianza de las fuerzas aleatorias se puede deducir del teorema de equipartición. Las simulaciones de dinámica molecular sin estas modificaciones, en cambio, mantienen la energía constante, simulando el formalismo microcanónico. En los sistemas fuera del límite termodinámico (como los que se suelen estudiar con estas técnicas) los distintos formalismos de la mecánica estadística no son equivalentes. Por ello, la dinámica de Langevin se usa muy frecuentemente dado que los sistemas reales no suelen ser aislados sino que están en contacto con un baño térmico.

Además de los parámetros que introdujimos en el capítulo \dots ahora debemos estimar el valor del coeficiente cinético de las partículas, $\xi$. Las propiedades de equilibrio no dependen de él (siempre que no sea nulo), por lo que hasta ahora lo habíamos tomado como la unidad, pero la dinámica sí que lo hace y en este capítulo analizaremos también propiedades dinámicas. Para estimar su valor nos valdremos de la fórmula de Stokes (aunque esta realmente se aplica únicamente a esferas aisladas), $\xi=3\pi\eta d$, donde $\eta$ es la viscosidad del agua y $d$ el diámetro de la partícula (en nuestro caso $\sigma$). Es conocido que a escala nanométrica en la dinámica dominan los efectos disipativos frente a los inerciales \cite{Purcell1977}, es decir, estamos en el régimen de bajo número de Reynolds. Debido a esto podemos despreciar el término inercial en \eqref{eq:Langevin} y utilizar la llamada dinámica Browniana cuyas ecuaciones del movimiento son,
\begin{equation}
    \label{eq:Brownian}
    \xi_i\frac{d\bar{r}_i}{dt}=-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t)
\end{equation}
Si bien es cierto que podríamos seguir empleando las ecuaciones del movimiento completas como hasta ahora para hacer simulaciones en el régimen sobreamortiguado, el paso temporal tan pequeño que sería necesario para que las simulaciones fueran precisas (o simplemente el algoritmo convergiera) las haría prohibitivamente largas.

Para resolver ecuaciones diferenciales estocásticas como \eqref{eq:Langevin} no se pueden utilizar los mismos métodos que para las ecuaciones diferenciales ordinarias, pero afortunadamente solo hay que modificarlos ligeramente para incluir correctamente los términos que son procesos estocásticos. Un algoritmo basado en el método de Runge-Kutta de segundo orden (también llamado método de Heun) \cite{Toral2014} aplicado a la ecuación de Langevin toma la siguiente forma,
\begin{equation}
    \label{eq:RK_method}
    \begin{aligned}
        (\bar{r}_i)'_{n}  & = (\bar{r}_i)_n+(\bar{v}_i)_ndt                                                                                         \\
        (\bar{v}_i)'_{n}  & = (\bar{v}_i)_n+\frac{1}{m_i}(\bar{f}_i)_ndt+\frac{1}{m_i}(\bar{u}_i)_n\sqrt{dt}                                        \\
        (\bar{r}_i)_{n+1} & = (\bar{r}_i)_n+\frac{1}{2}\left((\bar{v}_i)'_n+(\bar{v}_i)_n\right)dt                                                  \\
        (\bar{v}_i)_{n+1} & = (\bar{v}_i)_n+\frac{1}{2}\frac{1}{m_i}\left((\bar{f}_i)'_n+(\bar{f}_i)_n\right)dt+\frac{1}{m_i}(\bar{u}_i)_n\sqrt{dt}
    \end{aligned}
\end{equation}
donde
\begin{equation}
    \label{eq:RK_method_forces}
    (\bar{f}_i)_n=-\xi_i(\bar{v}_i)_n-\bar{\nabla}_iV(\{(\bar{r}_j)_n\}) \quad , \quad (\bar{f}_i)'_n=-\xi_i(\bar{v}_i)'_n-\bar{\nabla}_iV(\{(\bar{r}_j)'_n\})
\end{equation}
y cada componente de $(\bar{u}_i)_n$ es un número (pseudo)aleatorio con distribución normal, media nula y varianza $2\xi_ik_BT$. El mismo método aplicado a la ecuación \eqref{eq:Brownian} de la dinámica Browniana se reduce a
\begin{equation}
    \label{eq:RK_method_Brownian}
    \begin{aligned}
        (\bar{r}_i)'_{n}  & = (\bar{r}_i)_n+\frac{1}{\xi_i}(\bar{f}_i)_ndt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}                                        \\
        (\bar{r}_i)_{n+1} & = (\bar{r}_i)_n+\frac{1}{2}\frac{1}{\xi_i}\left((\bar{f}_i)'_n+(\bar{f}_i)_n\right)dt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}
    \end{aligned}
\end{equation}
donde ahora
\begin{equation}
    \label{eq:RK_method_forces_Brownian}
    (\bar{f}_i)_n=-\bar{\nabla}_iV(\{(\bar{r}_j)_n\}) \quad \text{y} \quad (\bar{f}_i)'_n=-\bar{\nabla}_iV(\{(\bar{r}_j)'_n\})
\end{equation}

\section{Programación en GPUs}

Este tipo de simulaciones suelen tener una gran cantidad de partículas y por lo tanto son muy costosas computacionalmente. Por esta razón es necesario aprovechar al máximo la potencia de cálculo del \textit{hardware} del que disponemos. Esta necesidad, común a muchas tareas de investigación, ha incentivado la computación de propósito general en GPUs (abreviada GPGPU, del inglés \textit{General-Purpose computing on Graphics Processing Units}). Las GPUs son procesadores diseñados para la generación de gráficos 3D pero dadas sus características también son muy apropiadas para propósitos científicos como la realización de simulaciones. Prueba de ello son los numerosos programas profesionales de dinámica molecular (GROMACS, NAMD, CHARMM, etc.) que están acelerados por GPU.

La característica de las GPUs (además de su precio) que las hace tan atractivas para estas aplicaciones es su gran paralelismo, es decir, su capacidad para ejecutar muchas instrucciones simultáneamente. El paralelismo puede ser de datos, si las instrucciones son las mismas pero se realizan sobre datos distintos, o de tareas, si las instrucciones son distintas. Las simulaciones de dinámica molecular se pueden beneficiar en gran medida del paralelismo ya que, en cada iteración, para hallar las nuevas coordenadas de una cierta partícula no necesitamos las nuevas coordenadas del resto, solo las viejas. En otras palabras, con un programa paralelo de simulación en una GPU podemos actualizar a la vez las coordenadas de una gran cantidad de partículas (aunque quizás no todas) ahorrando un tiempo de cálculo considerable\footnote{Las CPUs tienen frecuencias de reloj más altas que las GPUs por lo que pueden ser más rápidas si no hay muchas operaciones que realizar simultáneamente, esto es, si hay muy pocas partículas.}.

AÑADIR: Debido a la magnitud del sistema, que hasta hace poco había impedido estudiar el núcleo celular completo mediante simulaciones numéricas, será fundamental desarrollar este programa para que se ejecute en GPUs.

\cite{Wilt2013}

\dots

\section{Cálculo del volumen excluido}

En esta muestra utilizamos una malla uniforme [11], que es la subdivisión espacial más simple posible. (Las
técnicas descritas podrían extenderse a estructuras más sofisticadas, como las rejillas jerárquicas,
pero no lo discutiremos aquí).
Una malla uniforme subdivide el espacio de simulación en una malla de celdas de tamaño uniforme. Para simplificar
Para simplificar, utilizamos una rejilla en la que el tamaño de la celda es el mismo que el tamaño de la partícula (el doble de su radio). Esto significa que
cada partícula sólo puede cubrir un número limitado de celdas de la cuadrícula (8 en 3 dimensiones). Además, si suponemos que no hay
entre partículas, existe un límite superior fijo para el número de partículas por celda de cuadrícula (4 en 3 dimensiones).
(4 en 3 dimensiones).
Utilizamos una rejilla denominada «suelta», en la que cada partícula se asigna a una sola celda de la rejilla en función de su punto central.
punto central. Dado que cada partícula puede solaparse con varias celdas de la cuadrícula, al procesar las colisiones hay que examinar también el tamaño de la partícula.
al procesar las colisiones debemos examinar también las partículas de las celdas vecinas (3 x 3 x 3 = 27 en total) para ver si se tocan.
en total para ver si están en contacto con la partícula en cuestión. Este método nos permite agrupar las partículas
en las celdas de la rejilla simplemente ordenándolas por su índice de rejilla.
El método alternativo, en el que las partículas se almacenan en cada celda que tocan, requiere menos trabajo
al procesar las colisiones, pero más trabajo al construir la rejilla, y es generalmente más caro
en la GPU.
La estructura de datos de la malla se genera desde cero en cada paso temporal. Es posible realizar actualizaciones
Es posible realizar actualizaciones incrementales de la estructura de la malla en la GPU, pero este enfoque es simple y el rendimiento es constante independientemente del movimiento de las partículas.
constante independientemente del movimiento de las partículas.
Examinamos dos métodos diferentes para generar la estructura de rejilla.

El algoritmo consta de varios núcleos. El primer kernel «calcHash» calcula un valor hash para
cada partícula basado en su id de celda. En este ejemplo utilizamos simplemente el identificador de celda lineal como hash, pero
puede ser beneficioso utilizar otras funciones como la curva de orden Z [8] para mejorar la coherencia de los accesos a la memoria.
los accesos a la memoria. El núcleo almacena los resultados en la matriz «particleHash» de la memoria global como
un par uint2 (hash de celda, id de partícula).
A continuación, ordenamos las partículas en función de sus valores hash. La ordenación se realiza utilizando la ordenación rápida radix
proporcionado por la biblioteca CUDPP, que utiliza el algoritmo descrito en [12]. Esto crea una lista de
ids de partículas en orden de celda.
Para que esta lista ordenada sea útil, necesitamos ser capaces de encontrar el inicio de cualquier celda en la lista ordenada.
lista ordenada. Esto se consigue ejecutando otro kernel «findCellStart», que utiliza un hilo por partícula y compara el índice de celda de cada partícula.
partícula y compara el índice de celda de la partícula actual con el índice de celda de la partícula anterior en la lista ordenada.
en la lista ordenada. Si el índice es diferente, esto indica el inicio de una nueva celda, y la dirección de inicio es
en otra matriz mediante una escritura dispersa. El código actual también encuentra el índice del final de
cada celda de forma similar.

\dots

\cite{Green2010}

\begin{figure}
    \centering
    \includegraphics{../Plots/performance.pdf}
    \caption{Rendimiento.}
    \label{fig:performance}
\end{figure}
