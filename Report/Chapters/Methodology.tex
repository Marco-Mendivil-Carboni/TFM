\chapter{Metodología}
\label{cap:methodology}

\section{Dinámica Molecular}

En particular las simulaciones de dinámica molecular (MD) \cite{Rapaport2004} son aquellas en las que se resuelven numéricamente las ecuaciones del movimiento clásicas de un sistema de muchos cuerpos. Su nombre proviene de que, en virtud de la aproximación de Born-Oppenheimer, este método se puede y se suele utilizar para estudiar el movimiento de los núcleos atómicos en las moléculas, por lo que habitualmente, en las llamadas simulaciones MD \textit{all-atom}, cada una de las partículas representa uno de estos núcleos. Cuando se quieren simular macromoléculas (como en este trabajo), en cambio, es habitual usar modelos \textit{coarse-grained} en los que cada partícula representa un grupo de átomos. Al reducir los grados de libertad son posibles tiempos de simulación mucho mayores, a costa de perder algo de detalle.

Además, generalmente las moléculas que se quieren estudiar están inmersas en un solvente (casi siempre agua en contextos biológicos), que tiene efectos importantes sobre el comportamiento del soluto. Ahora bien, introducir explícitamente en las simulaciones las moléculas del solvente, que es de escaso interés en sí mismo, requiere de una gran cantidad de recursos y no suele ser necesario. En su lugar este se suele tener en cuenta de forma implícita \cite{Leach2001}, incorporando solo sus efectos sobre las partículas de la molécula: la modulación de los potenciales efectivos que actúan sobre ellas, la resistencia viscosa a su movimiento y las colisiones aleatorias de estas con las partículas del medio. El método más empleado para lograrlo es la dinámica de Langevin, que consiste simplemente en añadir a las ecuaciones del movimiento de la dinámica molecular una fuerza de fricción proporcional a la velocidad y una fuerza aleatoria que representa el efecto de estas colisiones. Es decir, que cada una de las partículas del sistema obedece la que se conoce como una ecuación de Langevin,
\begin{equation}
    \label{eq:Langevin}
    m_i\frac{d^2\bar{r}_i}{dt^2}=-\xi_i\frac{d\bar{r}_i}{dt}-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t)
\end{equation}
donde $m_i$ es la masa de la partícula $i$, $\xi_i$ es su coeficiente cinético y $\bar{\zeta}_i(t)$ es la fuerza aleatoria sobre ella. Los coeficientes cinéticos dependen del medio y la geometría de las partículas y los estimaremos más adelante. El potencial $V$ por supuesto depende, además del medio, de la molécula que se quiera simular, o mejor dicho, del modelo que se quiera utilizar para ello y será el tema central del capítulo \dots. Por último las fuerzas aleatorias dependen del medio y de los coeficientes cinéticos tal y como vamos a ver a continuación.

En realidad $\bar{\zeta}_i(t)$ no son funciones del tiempo en el sentido matemático habitual sino procesos estocásticos gaussianos con dos propiedades fundamentales:
\begin{equation}
    \label{eq:random_forces_properties}
    \langle \zeta_i^\alpha(t) \rangle=0 \quad \text{y} \quad \langle \zeta_i^\alpha(t)\zeta_j^\beta(t') \rangle=2\xi_ik_BT\delta_{ij}\delta_{\alpha\beta}\delta(t-t') \quad \forall \ i,j=1,\dots,N \land \alpha,\beta=x,y,z
\end{equation}
donde $k_B$ es la constante de Boltzmann y $T$ es la temperatura del medio. De esta forma, la dinámica de Langevin al introducir los efectos del solvente actúa simultáneamente como un termostato, permitiendo controlar la temperatura del sistema. Se puede demostrar \cite{Coffey2012} que esta ecuación efectivamente genera trayectorias que reproducen la distribución de probabilidad canónica. De hecho la varianza de las fuerzas aleatorias se puede deducir del teorema de equipartición. Las simulaciones de dinámica molecular sin estas modificaciones, en cambio, mantienen la energía constante, simulando el formalismo microcanónico. En los sistemas fuera del límite termodinámico (como los que se suelen estudiar con estas técnicas) los distintos formalismos de la mecánica estadística no son equivalentes. Por ello, la dinámica de Langevin se usa muy frecuentemente dado que los sistemas reales no suelen ser aislados sino que están en contacto con un baño térmico.

Además de los parámetros que introdujimos en el capítulo \dots ahora debemos estimar el valor del coeficiente cinético de las partículas, $\xi$. Las propiedades de equilibrio no dependen de él (siempre que no sea nulo), por lo que hasta ahora lo habíamos tomado como la unidad, pero la dinámica sí que lo hace y en este capítulo analizaremos también propiedades dinámicas. Para estimar su valor nos valdremos de la fórmula de Stokes (aunque esta realmente se aplica únicamente a esferas aisladas), $\xi=3\pi\eta d$, donde $\eta$ es la viscosidad del agua y $d$ el diámetro de la partícula (en nuestro caso $\sigma$). Es conocido que a escala nanométrica en la dinámica dominan los efectos disipativos frente a los inerciales \cite{Purcell1977}, es decir, estamos en el régimen de bajo número de Reynolds. Debido a esto podemos despreciar el término inercial en \eqref{eq:Langevin} y utilizar la llamada dinámica Browniana cuyas ecuaciones del movimiento son,
\begin{equation}
    \label{eq:Brownian}
    \xi_i\frac{d\bar{r}_i}{dt}=-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t)
\end{equation}
Si bien es cierto que podríamos seguir empleando las ecuaciones del movimiento completas como hasta ahora para hacer simulaciones en el régimen sobreamortiguado, el paso temporal tan pequeño que sería necesario para que las simulaciones fueran precisas (o simplemente el algoritmo convergiera) las haría prohibitivamente largas.

Para resolver ecuaciones diferenciales estocásticas como \eqref{eq:Langevin} no se pueden utilizar los mismos métodos que para las ecuaciones diferenciales ordinarias, pero afortunadamente solo hay que modificarlos ligeramente para incluir correctamente los términos que son procesos estocásticos. Un algoritmo basado en el método de Runge-Kutta de segundo orden (también llamado método de Heun) \cite{Toral2014} aplicado a la ecuación de Langevin toma la siguiente forma,
\begin{equation}
\label{eq:RK_method}
\begin{aligned}
    (\bar{r}_i)'_{n} &= (\bar{r}_i)_n+(\bar{v}_i)_ndt\\
    (\bar{v}_i)'_{n} &= (\bar{v}_i)_n+\frac{1}{m_i}(\bar{f}_i)_ndt+\frac{1}{m_i}(\bar{u}_i)_n\sqrt{dt}\\
    (\bar{r}_i)_{n+1} &= (\bar{r}_i)_n+\frac{1}{2}\left((\bar{v}_i)'_n+(\bar{v}_i)_n\right)dt\\
    (\bar{v}_i)_{n+1} &= (\bar{v}_i)_n+\frac{1}{2}\frac{1}{m_i}\left((\bar{f}_i)'_n+(\bar{f}_i)_n\right)dt+\frac{1}{m_i}(\bar{u}_i)_n\sqrt{dt}
\end{aligned}
\end{equation}
donde
\begin{equation}
    \label{eq:RK_method_forces}
    (\bar{f}_i)_n=-\xi_i(\bar{v}_i)_n-\bar{\nabla}_iV(\{(\bar{r}_j)_n\}) \quad , \quad (\bar{f}_i)'_n=-\xi_i(\bar{v}_i)'_n-\bar{\nabla}_iV(\{(\bar{r}_j)'_n\})
\end{equation}
y cada componente de $(\bar{u}_i)_n$ es un número (pseudo)aleatorio con distribución normal, media nula y varianza $2\xi_ik_BT$. El mismo método aplicado a la ecuación \eqref{eq:Brownian} de la dinámica Browniana se reduce a
\begin{equation}
\label{eq:RK_method_Brownian}
\begin{aligned}
    (\bar{r}_i)'_{n} &= (\bar{r}_i)_n+\frac{1}{\xi_i}(\bar{f}_i)_ndt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}\\
    (\bar{r}_i)_{n+1} &= (\bar{r}_i)_n+\frac{1}{2}\frac{1}{\xi_i}\left((\bar{f}_i)'_n+(\bar{f}_i)_n\right)dt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}
\end{aligned}
\end{equation}
donde ahora
\begin{equation}
    \label{eq:RK_method_forces_Brownian}
    (\bar{f}_i)_n=-\bar{\nabla}_iV(\{(\bar{r}_j)_n\}) \quad \text{y} \quad (\bar{f}_i)'_n=-\bar{\nabla}_iV(\{(\bar{r}_j)'_n\})
\end{equation}

\section{Programación en GPUs}

Este tipo de simulaciones suelen tener una gran cantidad de partículas y por lo tanto son muy costosas computacionalmente. Por esta razón es necesario aprovechar al máximo la potencia de cálculo del \textit{hardware} del que disponemos. Esta necesidad, común a muchas tareas de investigación, ha incentivado la computación de propósito general en GPUs (abreviada GPGPU, del inglés \textit{General-Purpose computing on Graphics Processing Units}). Las GPUs son procesadores diseñados para la generación de gráficos 3D pero dadas sus características también son muy apropiadas para propósitos científicos como la realización de simulaciones. Prueba de ello son los numerosos programas profesionales de dinámica molecular (GROMACS, NAMD, CHARMM, etc.) que están acelerados por GPU.

La característica de las GPUs (además de su precio) que las hace tan atractivas para estas aplicaciones es su gran paralelismo, es decir, su capacidad para ejecutar muchas instrucciones simultáneamente. El paralelismo puede ser de datos, si las instrucciones son las mismas pero se realizan sobre datos distintos, o de tareas, si las instrucciones son distintas. Las simulaciones de dinámica molecular se pueden beneficiar en gran medida del paralelismo ya que, en cada iteración, para hallar las nuevas coordenadas de una cierta partícula no necesitamos las nuevas coordenadas del resto, solo las viejas. En otras palabras, con un programa paralelo de simulación en una GPU podemos actualizar a la vez las coordenadas de una gran cantidad de partículas (aunque quizás no todas) ahorrando un tiempo de cálculo considerable\footnote{Las CPUs tienen frecuencias de reloj más altas que las GPUs por lo que pueden ser más rápidas si no hay muchas operaciones que realizar simultáneamente, esto es, si hay muy pocas partículas.}.

AÑADIR: Debido a la magnitud del sistema, que hasta hace poco había impedido estudiar el núcleo celular completo mediante simulaciones numéricas, será fundamental desarrollar este programa para que se ejecute en GPUs.

\cite{Wilt2013}

\dots

\section{Cálculo del volumen excluido}

\dots

\cite{Green2010}

\begin{figure}
  \centering
  \includegraphics{../Plots/performance.pdf}
  \caption{Rendimiento.}
  \label{fig:performance}
\end{figure}
