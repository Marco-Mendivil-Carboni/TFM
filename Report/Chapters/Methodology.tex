\chapter{Metodología}
\label{cap:methodology}

\section{Dinámica Molecular}

En este trabajo realizaremos concretamente simulaciones de dinámica molecular \cite{Rapaport2004}, que son aquellas en las que se resuelven numéricamente las ecuaciones del movimiento clásicas. Su nombre proviene de que, en virtud de la aproximación de Born-Oppenheimer, este método se puede y se suele utilizar para estudiar el movimiento de los núcleos atómicos en las moléculas. En las llamadas simulaciones MD \textit{all-atom}, cada una de las partículas representa uno de estos núcleos pero cuando se quieren simular macromoléculas como en este trabajo es habitual usar modelos \textit{coarse-grained} en los que cada partícula representa un grupo de átomos, como el que hemos descrito en el capítulo \ref{cap:chromatin}. Al reducir los grados de libertad son posibles tiempos de simulación mucho mayores, a costa de perder algo de detalle.

Pero además la cromatina (al igual que cualquier otra biomolécula) está inmersa en un solvente, el agua, que tiene efectos importantes sobre el comportamiento del soluto. Ahora bien, introducir explícitamente en las simulaciones las moléculas del solvente, que es de escaso interés en sí mismo, requiere de una gran cantidad de recursos y no suele ser necesario. En su lugar este se suele tener en cuenta de forma implícita \cite{Leach2001}, incorporando solo sus efectos sobre las partículas de nuestro modelo: la modulación de los potenciales efectivos que actúan sobre ellas, la resistencia viscosa a su movimiento y las colisiones aleatorias de estas con las partículas del medio. El método más empleado para lograrlo es la dinámica de Langevin, que consiste simplemente en añadir a las ecuaciones del movimiento de la dinámica molecular una fuerza de fricción proporcional a la velocidad y una fuerza aleatoria que representa el efecto de estas colisiones. Es decir, que cada una de las partículas del sistema obedece la que se conoce como una ecuación de Langevin,
\begin{equation}
    \label{eq:Langevin}
    m_i\frac{d^2\bar{r}_i}{dt^2}=-\xi_i\frac{d\bar{r}_i}{dt}-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t)
\end{equation}
donde $m_i$ es la masa de la partícula $i$, $\xi_i$ es su coeficiente cinético y $\bar{\zeta}_i(t)$ es la fuerza aleatoria sobre ella. Los coeficientes cinéticos dependen del medio y la geometría de las partículas y los estimaremos más adelante. Por último las fuerzas aleatorias dependen del medio y de los coeficientes cinéticos tal y como vamos a ver a continuación.

En realidad $\bar{\zeta}_i(t)$ no son funciones del tiempo en el sentido matemático habitual sino procesos estocásticos gaussianos con dos propiedades fundamentales:
\begin{equation}
    \label{eq:random_forces_properties}
    \langle \zeta_i^\alpha(t) \rangle=0 \quad \text{y} \quad \langle \zeta_i^\alpha(t)\zeta_j^\beta(t') \rangle=2\xi_ik_BT\delta_{ij}\delta_{\alpha\beta}\delta(t-t') \quad \forall \ i,j=1,\dots,N \land \alpha,\beta=x,y,z.
\end{equation}
De esta forma, la dinámica de Langevin al introducir los efectos del solvente actúa simultáneamente como un termostato, permitiendo controlar la temperatura del sistema. Se puede demostrar \cite{Coffey2012} que esta ecuación efectivamente genera trayectorias que reproducen la distribución de probabilidad canónica. De hecho la varianza de las fuerzas aleatorias se puede deducir del teorema de equipartición. Las simulaciones de dinámica molecular sin estas modificaciones, en cambio, mantienen la energía constante, simulando el formalismo microcanónico. En los sistemas fuera del límite termodinámico (como los que se suelen estudiar con estas técnicas) los distintos formalismos de la mecánica estadística no son equivalentes. Por ello, la dinámica de Langevin se usa muy frecuentemente dado que los sistemas reales no suelen ser aislados sino que están en contacto con un baño térmico.

Además de los parámetros que introdujimos en el capítulo \ref{cap:chromatin} ahora debemos estimar el valor del coeficiente cinético de las partículas, $\xi$. Las propiedades de equilibrio no dependen de él (siempre que no sea nulo) pero la dinámica sí que lo hace. Para estimar su valor nos valdremos de la fórmula de Stokes (aunque esta realmente se aplica únicamente a esferas aisladas), $\xi=3\pi\eta d=0.28$ pg/$\mu$s, donde $\eta$ es la viscosidad del agua y $d$ el diámetro de la partícula (en nuestro caso $\sigma$). Esto significa que el número de Reynolds en este sistema es $\text{Re}=\rho v_ul_u/\eta=1.7\cdot 10^{-5}$, es decir, estamos en el régimen de bajo número de Reynolds y en la dinámica dominan los efectos disipativos frente a los inerciales \cite{Purcell1977}. Debido a esto podemos despreciar el término inercial en \eqref{eq:Langevin} y utilizar la llamada dinámica Browniana cuyas ecuaciones del movimiento son,
\begin{equation}
    \label{eq:Brownian}
    \xi_i\frac{d\bar{r}_i}{dt}=-\bar{\nabla}_iV\left(\{\bar{r}_j\}\right)+\bar{\zeta}_i(t).
\end{equation}
Si bien es cierto que podríamos emplear las ecuaciones del movimiento completas para hacer simulaciones en el régimen sobreamortiguado, el paso temporal tan pequeño que sería necesario para que las simulaciones fueran precisas (o simplemente el algoritmo convergiera) las haría prohibitivamente largas.

Para resolver ecuaciones diferenciales estocásticas como \eqref{eq:Brownian} no se pueden utilizar los mismos métodos que para las ecuaciones diferenciales ordinarias, pero afortunadamente solo hay que modificarlos ligeramente para incluir correctamente los términos que son procesos estocásticos. Un algoritmo basado en el método de Runge-Kutta de segundo orden (también llamado método de Heun) \cite{Toral2014} aplicado a la ecuación de la dinámica Browniana toma la siguiente forma,
\begin{equation}
    \label{eq:RK_method}
    \begin{aligned}
        (\bar{r}_i)'_{n}  & = (\bar{r}_i)_n+\frac{1}{\xi_i}(\bar{f}_i)_ndt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}                                        \\
        (\bar{r}_i)_{n+1} & = (\bar{r}_i)_n+\frac{1}{2}\frac{1}{\xi_i}\left((\bar{f}_i)'_n+(\bar{f}_i)_n\right)dt+\frac{1}{\xi_i}(\bar{u}_i)_n\sqrt{dt}
    \end{aligned}
\end{equation}
donde
\begin{equation}
    \label{eq:RK_method_forces}
    (\bar{f}_i)_n=-\bar{\nabla}_iV(\{(\bar{r}_j)_n\}) \quad \text{y} \quad (\bar{f}_i)'_n=-\bar{\nabla}_iV(\{(\bar{r}_j)'_n\})
\end{equation}
y cada componente de $(\bar{u}_i)_n$ es un número (pseudo)aleatorio con distribución normal, media nula y varianza $2\xi_ik_BT$.

\section{Programación en GPUs}

Este simulaciones tendrán una gran cantidad de partículas ($30386$) y por lo tanto serán muy costosas computacionalmente, lo cual hasta hace poco había impedido estudiar el núcleo celular completo mediante simulaciones numéricas. Por esta razón es necesario aprovechar al máximo la potencia de cálculo del \textit{hardware} del que disponemos. Esta necesidad, común a muchas tareas de investigación, ha incentivado la computación de propósito general en GPUs (abreviada GPGPU, del inglés \textit{General-Purpose computing on Graphics Processing Units}). Las GPUs son procesadores diseñados para la generación de gráficos 3D pero dadas sus características también son muy apropiadas para propósitos científicos como la realización de simulaciones. Prueba de ello son los numerosos programas profesionales de dinámica molecular (GROMACS, NAMD, CHARMM, etc.) que están acelerados por GPU.

La característica de las GPUs (además de su precio) que las hace tan atractivas para estas aplicaciones es su gran paralelismo, es decir, su capacidad para ejecutar muchas instrucciones simultáneamente. Las simulaciones de dinámica molecular se pueden beneficiar en gran medida del paralelismo ya que, en cada iteración, para hallar las nuevas coordenadas de una cierta partícula no necesitamos las nuevas coordenadas del resto, solo las viejas. En otras palabras, con un programa paralelo de simulación en una GPU podemos actualizar a la vez las coordenadas de una gran cantidad de partículas (aunque quizás no todas) ahorrando un tiempo de cálculo considerable\footnote{Las CPUs tienen frecuencias de reloj más altas que las GPUs por lo que pueden ser más rápidas si no hay muchas operaciones que realizar simultáneamente, esto es, si hay muy pocas partículas.}.

Aunque hay muchas herramientas para el desarrollo de \textit{software} GPGPU el estándar, especialmente en el ámbito científico, es CUDA \cite{Wilt2013} (\textit{Compute Unified Device Architecture}): una plataforma de computación en paralelo creada por NVIDIA que permite ejecutar en GPUs de esta empresa programas escritos utilizando CUDA C, una variación del lenguaje C.

\section{Cálculo del volumen excluido}

Como anticipamos en el capítulo \ref{cap:introduction} la interacción de volumen excluido será la más costosa computacionalmente y por ello creemos conveniente mostrar el algoritmo que se ha empleado para el cálculo de las fuerzas debidas a la misma. Por simplicidad puede ser tentador implementar esta interacción de forma \textit{naive} calculando las distancias entre todas las parejas de partículas, pero este método es $\mathcal{O}(N^2)$ y hay algoritmos, como el que vamos a ver, cualitativamente mejores.

Este algoritmo \cite{Green2010} \dots

En esta muestra utilizamos una malla uniforme [11], que es la subdivisión espacial más simple posible. (Las
técnicas descritas podrían extenderse a estructuras más sofisticadas, como las rejillas jerárquicas,
pero no lo discutiremos aquí).
Una malla uniforme subdivide el espacio de simulación en una malla de celdas de tamaño uniforme. Para simplificar
Para simplificar, utilizamos una rejilla en la que el tamaño de la celda es el mismo que el tamaño de la partícula (el doble de su radio). Esto significa que
cada partícula sólo puede cubrir un número limitado de celdas de la cuadrícula (8 en 3 dimensiones). Además, si suponemos que no hay
entre partículas, existe un límite superior fijo para el número de partículas por celda de cuadrícula (4 en 3 dimensiones).
(4 en 3 dimensiones).
Utilizamos una rejilla denominada «suelta», en la que cada partícula se asigna a una sola celda de la rejilla en función de su punto central.
punto central. Dado que cada partícula puede solaparse con varias celdas de la cuadrícula, al procesar las colisiones hay que examinar también el tamaño de la partícula.
al procesar las colisiones debemos examinar también las partículas de las celdas vecinas (3 x 3 x 3 = 27 en total) para ver si se tocan.
en total para ver si están en contacto con la partícula en cuestión. Este método nos permite agrupar las partículas
en las celdas de la rejilla simplemente ordenándolas por su índice de rejilla.
El método alternativo, en el que las partículas se almacenan en cada celda que tocan, requiere menos trabajo
al procesar las colisiones, pero más trabajo al construir la rejilla, y es generalmente más caro
en la GPU.
La estructura de datos de la malla se genera desde cero en cada paso temporal. Es posible realizar actualizaciones
Es posible realizar actualizaciones incrementales de la estructura de la malla en la GPU, pero este enfoque es simple y el rendimiento es constante independientemente del movimiento de las partículas.
constante independientemente del movimiento de las partículas.
Examinamos dos métodos diferentes para generar la estructura de rejilla.
El algoritmo consta de varios núcleos. El primer kernel «calcHash» calcula un valor hash para
cada partícula basado en su id de celda. En este ejemplo utilizamos simplemente el identificador de celda lineal como hash, pero
puede ser beneficioso utilizar otras funciones como la curva de orden Z [8] para mejorar la coherencia de los accesos a la memoria.
los accesos a la memoria. El núcleo almacena los resultados en la matriz «particleHash» de la memoria global como
un par uint2 (hash de celda, id de partícula).
A continuación, ordenamos las partículas en función de sus valores hash. La ordenación se realiza utilizando la ordenación rápida radix
proporcionado por la biblioteca CUDPP, que utiliza el algoritmo descrito en [12]. Esto crea una lista de
ids de partículas en orden de celda.
Para que esta lista ordenada sea útil, necesitamos ser capaces de encontrar el inicio de cualquier celda en la lista ordenada.
lista ordenada. Esto se consigue ejecutando otro kernel «findCellStart», que utiliza un hilo por partícula y compara el índice de celda de cada partícula.
partícula y compara el índice de celda de la partícula actual con el índice de celda de la partícula anterior en la lista ordenada.
en la lista ordenada. Si el índice es diferente, esto indica el inicio de una nueva celda, y la dirección de inicio es
en otra matriz mediante una escritura dispersa. El código actual también encuentra el índice del final de
cada celda de forma similar.

\begin{figure}
    \centering
    \includegraphics{../Plots/performance.pdf}
    \caption{Rendimiento.}
    \label{fig:performance}
\end{figure}


\begin{figure}
    \centering
    \begin{tikzpicture}[scale=2]
        \draw[color1,fill=color1,fill opacity=0.25] (1.7,1.2) circle (0.5) node [opacity=1] {0};
        \draw[color1,fill=color1,fill opacity=0.25] (2.9,2.1) circle (0.5) node [opacity=1] {1};
        \draw[color1,fill=color1,fill opacity=0.25] (2.1,2.4) circle (0.5) node [opacity=1] {2};
        \draw[color1,fill=color1,fill opacity=0.25] (0.9,2.1) circle (0.5) node [opacity=1] {3};
        \draw[color1,fill=color1,fill opacity=0.25] (2.8,2.8) circle (0.5) node [opacity=1] {4};
        \draw[color1,fill=color1,fill opacity=0.25] (0.6,2.8) circle (0.5) node [opacity=1] {5};
        \foreach \i in {0,...,4} {\draw[black] (\i,0) -- (\i,4);}
        \foreach \j in {0,...,4} {\draw[black] (0,\j) -- (4,\j);}
        \foreach \i in {0,...,3} {\foreach \j [evaluate=\num using int(\i+4*\j)] in {0,...,3} {\node[above right] at (\i,\j) {\num};}}
    \end{tikzpicture}
    \caption{\dots}
    \label{fig:grid-diagram}
\end{figure}
